<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>David B. Lindell | ACORN: Adaptive coordinate networks for neural scene representation</title>
<meta name="description" content="">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<!-- <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />  -->

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/publications/acorn">

<!-- Theming-->



  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-85065092-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-85065092-1');
  </script>


    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-md fixed-top z-depth-1">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">David B.  Lindell</span>
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/people/">
                people
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
          <li class="nav-item">
              <a class="nav-link" href="/assets/pdf/cv.pdf">
                CV
                <span class="sr-only">(current)</span>
              </a>
          </li>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="row">
        <div class="col-sm-12 mx-auto">
            <h3>ACORN: Adaptive coordinate networks for neural scene representation</h3>
          <p class="name"> Julien N. P. Martel*, <strong>David B. Lindell*</strong>, Connor Z. Lin, Eric R. Chan, Marco Monteiro, Gordon Wetzstein </p>
          <ul class="list-inline">

              
              <li class="list-inline-item"> 
                  <a class="btn" target="_blank" title="Download PDF" href="https://arxiv.org/abs/2105.02788"><i class="fa fa-lg fa-file-pdf"></i> PDF</a>
              </li>
              

              

              
              <li class="list-inline-item">
                  <a class="btn" target="_blank" title="Code" href="https://github.com/computational-imaging/acorn"><i class="fa fa-lg fa-code"></i> Code</a>
              </li>
              

              


              
              <li class="list-inline-item">
                  <a class="btn" target="_blank" title="Video" href="https://www.youtube.com/watch?v=P192X3J6cg4"><i class="fa fa-lg fa-video"></i> Video</a>
              </li>
              

          </ul>

          

        </div>
      </div>

      <hr class="star-primary">
      <div class="row">
        <div class="center-block col-sm-8 mx-auto">
          <img src="/assets/img/publication/siggraph2021martel.png" class="img-fluid" alt="image-alt">
        </div>
      </div>
      <hr class="star-primary">


      <p style="text-align: left;"><strong>An adaptive multiscale neural network architecture for representing large-scale scenes.</strong></p>

<h3 id="video">Video</h3>
<hr />
<div class="embed-responsive embed-responsive-16by9">
<iframe class="embed-repsonsive-item" src="https://www.youtube.com/embed/P192X3J6cg4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</div>
<p><br /></p>

<h3 id="abstract">Abstract</h3>
<hr />
<p>Neural representations have emerged as a new paradigm for applications in rendering, imaging, geometric modeling, and simulation. Compared to traditional representations such as meshes, point clouds, or volumes they can be flexibly incorporated into differentiable learning-based pipelines. While recent improvements to neural representations now make it possible to represent signals with fine details at moderate resolutions (e.g., for images and 3D shapes), adequately representing large-scale or complex scenes has proven a challenge. Current neural representations fail to accurately represent images at resolutions greater than a megapixel or 3D scenes with more than a few hundred thousand polygons. Here, we introduce a new hybrid implicit-explicit network architecture and training strategy that adaptively allocates resources during training and inference based on the local complexity of a signal of interest. Our approach uses a multiscale block-coordinate decomposition, similar to a quadtree or octree, that is optimized during training. The network architecture operates in two stages: using the bulk of the network parameters, a coordinate encoder generates a feature grid in a single forward pass. Then, hundreds or thousands of samples within each block can be efficiently evaluated using a lightweight feature decoder. With this hybrid implicit-explicit network architecture, we demonstrate the first experiments that fit gigapixel images to nearly 40 dB peak signal-to-noise ratio. Notably this represents an increase in scale of over 1000x compared to the resolution of previously demonstrated image-fitting experiments. Moreover, our approach is able to represent 3D shapes significantly faster and better than previous techniques; it reduces training times from days to hours or minutes and memory requirements by over an order of magnitude.</p>

<h3 style="text-align: left;" id="acorn-framework">ACORN Framework</h3>
<hr />
<div class="row">
<div class="col-sm-12 mx-auto">
<img src="/assets/img/publication/siggraph2021martel/acorn_method.png" class="img-fluid" alt="" />
</div>
</div>
<p><br /></p>

<p style="text-align: left;"><strong>ACORN hybrid implicit–explicit architecture.</strong> Space is partitioned in blocks whose coordinates are fed to an encoder that produces a feature-grid. A set of local coordinates are used to address the feature grid, at any arbitrary position using linear intepolation, and yield a feature vector. The feature vector is the input of a lightweight neural network decoder that produces the signal of interest.</p>

<div class="row">
<div class="col-sm-8 mx-auto">
<img src="/assets/img/publication/siggraph2021martel/acorn_pluto.png" style="" class="img-fluid" alt="" />
</div>
</div>
<p><br /></p>

<p style="text-align: left;"><strong>ACORN fits images better and faster.</strong> ACORN can fit this pluto image at a 4096×4096 resolution up to 30 dB in about 30 seconds, which is more than 2 orders of magnitude faster than conventional global implicit representations such as SIREN or MLPs using RELU with positional encoding.</p>

<div class="row">
<div class="col-sm-12 mx-auto">
<video preload="auto" autoplay="" muted="" loop="loop" style="display: block; width: 100%; height: auto;" src="/assets/img/publication/siggraph2021martel/pluto_compare.webm" type="video/webm" class="">
</video>
</div>
</div>
<p><br /></p>

<p style="text-align: left;"><strong>Comparison of ACORN vs SIREN over 60s of fitting a 16 MP image.</strong></p>

<h3 id="fitting-a-gigapixel-image">Fitting a Gigapixel Image</h3>
<hr />

<div class="row">
<div class="col-sm-12 mx-auto">
<video preload="auto" autoplay="" muted="" loop="loop" style="display: block; width: 100%; height: auto;" src="/assets/img/publication/siggraph2021martel/gigapix_fitting.webm" type="video/webm" class="">
</video>
</div>
</div>
<p><br /></p>

<p style="text-align: left;"><strong>An image with 1 billion pixels (gigapixel) rendered using ACORN.</strong></p>

<h3 id="fitting-high-detail-3d-shapes">Fitting High-Detail 3D Shapes</h3>
<hr />

<div class="row">
<div class="col-sm-8 mx-auto">
<img src="/assets/img/publication/siggraph2021martel/dragon.png" style="" class="img-fluid" alt="" />
</div>
</div>
<p><br /></p>

<p style="text-align: left;"><strong>ACORN fitting a 3D model of a dragon and a visualization of the adaptive block decomposition.</strong></p>

<div class="row">
<div class="col-sm-8 mx-auto">
<img src="/assets/img/publication/siggraph2021martel/lucy.png" style="" class="img-fluid" alt="" />
</div>
</div>
<p><br /></p>

<p style="text-align: left;"><strong>ACORN fitting a 3D model of Lucy (Stanford 3D model repository) and a visualization of the adaptive block decomposition.</strong></p>

<div class="row">
<div class="col-sm-8 mx-auto">
<video preload="auto" autoplay="" muted="" loop="loop" style="display: block; width: 100%; height: auto;" src="/assets/img/publication/siggraph2021martel/statue_decomp.webm" type="video/webm" class="">
</video>
</div>
</div>
<p style="text-align: left;"><br />
<strong>Learned block decomposition of the Thai statue model.</strong></p>

<div class="row">
<div class="col-sm-8 mx-auto">
<video preload="auto" autoplay="" muted="" loop="loop" style="display: block; width: 100%; height: auto;" src="/assets/img/publication/siggraph2021martel/engine_decomp.webm" type="video/webm" class="">
</video>
</div>
</div>
<p style="text-align: left;"><br />
<strong>Learned block decomposition of the engine model.</strong></p>

<h3 id="acknowledgments">Acknowledgments</h3>
<hr />
<p style="text-align: left;">J.N.P. Martel was supported by a Swiss National Foundation (SNF) Fellowship (P2EZP2 181817). C.Z. Lin was supported by a David Cheriton Stanford Graduate Fellowship. G.W. was supported by an Okawa Research Grant, a Sloan Fellowship, and a PECASE by the ARO. Other funding for the project was provided by NSF (award numbers 1553333 and 1839974).</p>

<h3 id="citation">Citation</h3>
<hr />
<div style="text-align: left;" class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
@article{martel2021acorn,
author = {Martel, Julien N.P. and Lindell, David B. and Lin, Connor Z. and Chan, Eric R. and Monteiro, Marco and Wetzstein, Gordon},
title = {ACORN: Adaptive Coordinate Networks for Neural Representation},
booktitle = {ACM Trans. Graph. (SIGGRAPH)},
year={2021}
}

</code></pre></div></div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom z-depth-1">
  <div class="container mt-0">
    &copy; Copyright 2025 David B. Lindell.
    
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="text/javascript" charset="utf8" src="https://cdn.datatables.net/1.10.22/js/jquery.dataTables.js"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<!-- <script src="/assets/js/dark_mode.js"></script>-->


</html>
